# -*- coding: utf-8 -*-
import io
import os
import re
import threading
import time
import base64
import json
import secrets
import tempfile
import traceback
from flask import Flask, request, abort, Response
import requests
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, TextSendMessage, PostbackEvent, AudioMessage,
    QuickReply, QuickReplyButton, MessageAction, FlexSendMessage,
)
from linebot.models.send_messages import AudioSendMessage
from upstash_redis import Redis
from openai import OpenAI
import httpx
from httpx_retries import RetryTransport, Retry
import cloudinary
import cloudinary.uploader

try:
    from api.syllabus import (
        is_off_topic,
        get_rag_instructions,
        get_writing_mode_instructions,
        is_course_inquiry_intent,
        build_course_inquiry_flex,
        OFF_TOPIC_REPLY,
    )
    from api.learning import (
        log_question,
        set_last_question,
        get_last_question,
        set_last_assistant_message,
        get_last_assistant_message,
        set_quiz_pending,
        get_quiz_pending,
        clear_quiz_pending,
        set_user_state,
        get_user_state,
        set_quiz_data,
        get_quiz_data,
        clear_quiz_data,
        STATE_NORMAL,
        STATE_QUIZ_WAITING,
        record_weak_category,
        get_weak_categories,
        clear_weak_category,
        get_last_review_ask,
        set_last_review_ask,
        set_pending_review_category,
        get_pending_review_category,
        clear_pending_review_category,
        generate_dynamic_quiz,
        reveal_quiz_answer,
        judge_quiz_answer,
        generate_review_note,
    )
except ImportError:
    from syllabus import (
        is_off_topic,
        get_rag_instructions,
        get_writing_mode_instructions,
        is_course_inquiry_intent,
        build_course_inquiry_flex,
        OFF_TOPIC_REPLY,
    )
    from learning import (
        log_question,
        set_last_question,
        get_last_question,
        set_last_assistant_message,
        get_last_assistant_message,
        set_quiz_pending,
        get_quiz_pending,
        clear_quiz_pending,
        set_user_state,
        get_user_state,
        set_quiz_data,
        get_quiz_data,
        clear_quiz_data,
        STATE_NORMAL,
        STATE_QUIZ_WAITING,
        record_weak_category,
        get_weak_categories,
        clear_weak_category,
        get_last_review_ask,
        set_last_review_ask,
        set_pending_review_category,
        get_pending_review_category,
        clear_pending_review_category,
        generate_dynamic_quiz,
        reveal_quiz_answer,
        judge_quiz_answer,
        generate_review_note,
    )

# 1. åˆå§‹åŒ–ï¼ˆä¿ç•™åŸæœ‰ upstash_redis é€£ç·šè¨­å®šï¼‰
app = Flask(__name__)
line_bot_api = LineBotApi(os.getenv('LINE_CHANNEL_ACCESS_TOKEN'))
line_webhook_handler = WebhookHandler(os.getenv('LINE_CHANNEL_SECRET'))
# ä½¿ç”¨ httpx + RetryTransport ç·©è§£ Vercel ä¸Š Errno 16 "Device or resource busy" ç­‰ç¬æ–·
_retry = Retry(total=3, backoff_factor=0.5)
_http_client = httpx.Client(
    transport=RetryTransport(retry=_retry),
    limits=httpx.Limits(max_keepalive_connections=5, max_connections=20),
)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"), http_client=_http_client)
assistant_id = os.getenv("OPENAI_ASSISTANT_ID")

kv_url = os.getenv("KV_REST_API_URL")
kv_token = os.getenv("KV_REST_API_TOKEN")
redis = Redis(url=kv_url, token=kv_token) if kv_url and kv_token else None

# Cloudinary è¨­å®šï¼ˆTTS èªéŸ³æª”é›²ç«¯å„²å­˜ï¼‰
_cloudinary_configured = bool(
    os.getenv("CLOUDINARY_CLOUD_NAME")
    and os.getenv("CLOUDINARY_API_KEY")
    and os.getenv("CLOUDINARY_API_SECRET")
)
if _cloudinary_configured:
    cloudinary.config(
        cloud_name=os.getenv("CLOUDINARY_CLOUD_NAME"),
        api_key=os.getenv("CLOUDINARY_API_KEY"),
        api_secret=os.getenv("CLOUDINARY_API_SECRET"),
    )

# å®‰å…¨è²æ˜ï¼šæ¶‰åŠä¸­é†«è¨ºæ–·ä¹‹å›è¦†å¿…é ˆé™„åŠ 
SAFETY_DISCLAIMER = "\n\nâš ï¸ åƒ…ä¾›æ•™å­¸ç”¨é€”ï¼Œä¸å…·é†«ç™‚å»ºè­°ã€‚"

VOICE_COACH_TTS_VOICE = "shimmer"
TIMEOUT_SECONDS = 28  # Assistant + RAG å¸¸éœ€ 15â€“30 ç§’ï¼›ä¿ç•™ buffer é¿é–‹ Vercel é è¨­ 30s
TIMEOUT_MESSAGE = "æ­£åœ¨åŠªåŠ›ç¿»é–±å…¸ç±/è³‡æ–™ä¸­ï¼Œè«‹ç¨å€™å†å•æˆ‘ä¸€æ¬¡ã€‚"

# --- å£èªªç·´ç¿’ï¼šç³¾éŒ¯èˆ‡åˆ†æå¤§è…¦ ---
def _evaluate_speech(transcript):
    """
    ç³¾éŒ¯èˆ‡åˆ†æï¼šæª¢æŸ¥èªæ³•ã€æ‹¼å¯«ã€ç”¨è©ã€èªç¾©å®Œæ•´æ€§ã€‚
    å›å‚³ (status: "Correct"|"NeedsImprovement", feedback_text: str, corrected_text: str ç”¨æ–¼ TTS)ã€‚
    """
    if not (transcript or "").strip():
        return "Correct", "", ""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯è‹±æ–‡ç™¼éŸ³èˆ‡æ–‡æ³•åŠ©æ•™ã€‚åˆ†æå­¸ç”ŸèªéŸ³è¾¨è­˜æ–‡å­—ï¼ŒåŸ·è¡Œï¼š\n"
                        "1. æª¢æŸ¥èªæ³•éŒ¯èª¤ã€å–®å­—æ‹¼å¯«éŒ¯èª¤ã€ç”¨è©ä¸ç•¶\n"
                        "2. è©•ä¼°èªç¾©æ˜¯å¦å®Œæ•´\n"
                        "å›å‚³ JSONï¼š\n"
                        '{"status": "Correct" æˆ– "NeedsImprovement", "feedback": "ç°¡çŸ­å›é¥‹ï¼ˆéœ€æ”¹é€²è™•æˆ–é¼“å‹µï¼‰", "corrected": "ä¿®æ­£å¾Œçš„æ­£ç¢ºæ–‡æœ¬ï¼ˆè‹¥ status ç‚º Correct å‰‡ç‚ºç©ºå­—ä¸²ï¼‰"}\n'
                        "Status: Correct = å®Œå…¨æ­£ç¢ºä¸”è‡ªç„¶ï¼›NeedsImprovement = æœ‰ä»»ä½•ç´°å¾®éŒ¯èª¤ã€‚"
                    ),
                },
                {"role": "user", "content": f"å­¸ç”Ÿèªªå‡ºçš„å…§å®¹ï¼š{transcript[:500]}"},
            ],
            max_tokens=250,
        )
        raw_text = (resp.choices[0].message.content or "").strip()
        for block in (raw_text.split("```"), [raw_text]):
            for raw in block:
                raw = raw.strip()
                if raw.startswith("{"):
                    try:
                        obj = json.loads(raw.split("```")[0].strip().split("\n")[0])
                        status = (obj.get("status") or "Correct").strip()
                        if status not in ("Correct", "NeedsImprovement"):
                            status = "Correct" if obj.get("correct", True) else "NeedsImprovement"
                        feedback = (obj.get("feedback") or "").strip()[:400]
                        corrected = (obj.get("corrected") or "").strip()[:500]
                        return status, feedback, corrected
                    except Exception:
                        pass
    except Exception:
        traceback.print_exc()
    return "Correct", "", ""

def _upload_tts_to_cloudinary(audio_bytes, sentence=""):
    """ä¸Šå‚³ TTS èªéŸ³è‡³ Cloudinaryï¼ˆBytesIO ä¸²æµã€video è³‡æºå‹åˆ¥å„ªåŒ–éŸ³è¨Šï¼‰ï¼Œå›å‚³ (secure_url, duration_ms)ã€‚"""
    if not _cloudinary_configured or not audio_bytes:
        return (None, 0)
    try:
        result = cloudinary.uploader.upload(
            io.BytesIO(audio_bytes),
            resource_type="video",  # éŸ³è¨Šç”¨ video å‹åˆ¥ï¼Œæ”¯æ´è½‰ç¢¼èˆ‡ CDN å„ªåŒ–
            folder="tts",
            use_filename=True,
            unique_filename=True,
        )
        url = result.get("secure_url")
        if url:
            duration_ms = max(1000, int(len(sentence.split()) / 2.2 * 1000))
            return (url, duration_ms)
    except Exception:
        traceback.print_exc()
    return (None, 0)


def _generate_tts_and_store(sentence, voice=None):
    """OpenAI TTS (model: tts-1) ç”¢ç”ŸèªéŸ³ï¼Œç›´æ¥ BytesIO ä¸²æµä¸Šå‚³ Cloudinaryï¼Œç„¡ç¡¬ç¢Ÿå¯«å…¥ã€‚"""
    voice = voice or "shimmer"
    if not (sentence or "").strip():
        return (None, 0)
    token = secrets.token_urlsafe(12)
    vercel_url = (os.getenv("VERCEL_URL") or "").strip().rstrip("/")
    if vercel_url:
        base_url = f"https://{vercel_url}" if not vercel_url.startswith("http") else vercel_url
    else:
        base_url = (request.host_url.rstrip("/") if request else "") or "https://placeholder.vercel.app"
    try:
        resp = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=sentence[:4096],
        )
        audio_bytes = resp.content
        duration_ms = max(1000, int(len(sentence.split()) / 2.2 * 1000))

        # å„ªå…ˆä¸Šå‚³ Cloudinaryï¼Œå–å¾— HTTPS Secure URL
        if _cloudinary_configured:
            cloud_url, cloud_dur = _upload_tts_to_cloudinary(audio_bytes, sentence)
            if cloud_url:
                return (cloud_url, cloud_dur or duration_ms)

        # å¾Œå‚™ï¼šå­˜ Redisï¼Œä½¿ç”¨ /audio/<token> è·¯ç”±
        b64 = base64.b64encode(audio_bytes).decode("ascii")
        try:
            if redis:
                redis.set(f"tts_audio:{token}", b64, ex=600)
        except Exception:
            pass
        return (f"{base_url}/audio/{token}", duration_ms)
    except Exception:
        traceback.print_exc()
        return (None, 0)

# --- èª²å‹™æŸ¥è©¢ Flex Messageï¼ˆèˆ‡æœ¬é€±é‡é»æ•´åˆï¼‰---
def send_course_inquiry_flex(user_id, reply_token=None):
    """ç™¼é€èª²å‹™æŸ¥è©¢ Flex Messageï¼ˆå«ç•¶é€±/ä¸‹é€±åˆ‡æ›ã€AI é‡é»ã€è©•é‡ã€é‡è¦æ—¥æœŸï¼‰ã€‚reply_token æœ‰å€¼å‰‡ replyï¼Œå¦å‰‡ pushã€‚"""
    bubble = build_course_inquiry_flex(client)
    flex_msg = FlexSendMessage(
        alt_text="ğŸ“‹ èª²å‹™æŸ¥è©¢èˆ‡æœ¬é€±é‡é»",
        contents=bubble,
        quick_reply=quick_reply_items(),
    )
    if reply_token:
        line_bot_api.reply_message(reply_token, flex_msg)
    else:
        line_bot_api.push_message(user_id, flex_msg)

# --- QuickReply ---
def quick_reply_items():
    return QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label="å£èªªç·´ç¿’", text="å£èªªç·´ç¿’")),
            QuickReplyButton(action=MessageAction(label="å¯«ä½œä¿®æ”¹", text="å¯«ä½œä¿®æ”¹")),
            QuickReplyButton(action=MessageAction(label="èª²å‹™æŸ¥è©¢", text="èª²å‹™æŸ¥è©¢")),
            QuickReplyButton(action=MessageAction(label="æœ¬é€±é‡é»", text="æœ¬é€±é‡é»")),
        ]
    )

def text_with_quick_reply(content):
    return TextSendMessage(text=content, quick_reply=quick_reply_items())

def quick_reply_speak_practice():
    """å£èªªç·´ç¿’ï¼šè¦å†ç·´ç¿’ä¸‹ä¸€å¥å—ï¼Ÿ[ç·´ç¿’ä¸‹ä¸€å¥] [çµæŸç·´ç¿’]ã€‚"""
    return QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label="ç·´ç¿’ä¸‹ä¸€å¥", text="ç·´ç¿’ä¸‹ä¸€å¥")),
            QuickReplyButton(action=MessageAction(label="çµæŸç·´ç¿’", text="çµæŸç·´ç¿’")),
        ]
    )

def text_with_quick_reply_speak_practice(content):
    return TextSendMessage(text=content, quick_reply=quick_reply_speak_practice())

def quick_reply_quiz_ask():
    """æ¯å€‹å›ç­”å¾Œè©¢å•ï¼šè¦ä¾†è©¦è©¦ä¸€é¡Œå°æ¸¬é©—å—ï¼Ÿ[æ˜¯, å¦]ã€‚"""
    return QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label="æ˜¯", text="æ˜¯")),
            QuickReplyButton(action=MessageAction(label="å¦", text="å¦")),
        ]
    )

def text_with_quick_reply_quiz(content):
    return TextSendMessage(text=content, quick_reply=quick_reply_quiz_ask())


def build_quiz_flex_message(question):
    """å»ºç«‹æ¸¬é©—é¡Œç›® Flex Messageï¼ˆå­¸ç”Ÿçš„å›ç­”å°‡è¦–ç‚ºæ–°å•é¡Œï¼‰ã€‚"""
    bubble = {
        "type": "bubble",
        "body": {
            "type": "box",
            "layout": "vertical",
            "spacing": "md",
            "contents": [
                {"type": "text", "text": "ğŸ“ ä¸€é¡Œå°æ¸¬é©—", "weight": "bold", "size": "lg"},
                {"type": "text", "text": question, "wrap": True, "size": "sm"},
            ],
        },
    }
    alt = f"å°æ¸¬é©—ï¼š{(question or '')[:80]}"
    if len(question or "") > 80:
        alt += "..."
    return FlexSendMessage(alt_text=alt, contents=bubble)

def quick_reply_review_ask():
    """ä¸»å‹•è¤‡ç¿’ï¼šéœ€è¦å¹«ä½ æ•´ç†è¤‡ç¿’ç­†è¨˜å—ï¼Ÿ[è¦, ä¸è¦]ã€‚"""
    return QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label="è¦", text="è¦è¤‡ç¿’ç­†è¨˜")),
            QuickReplyButton(action=MessageAction(label="ä¸è¦", text="ä¸è¦è¤‡ç¿’ç­†è¨˜")),
        ]
    )

def text_with_quick_reply_review_ask(content):
    return TextSendMessage(text=content, quick_reply=quick_reply_review_ask())

# --- å¯«ä½œä¿®è¨‚æ¨¡å¼ï¼šç¨ç«‹è™•ç†ï¼Œä¸ç¶“é Assistant API / RAG ---
REVISION_MODE = "writing"

def _revision_handler(user_id, text):
    """
    å¯«ä½œä¿®è¨‚å°ˆå±¬è™•ç†ï¼šä½¿ç”¨ Chat Completions APIï¼Œä¸èª¿ç”¨ä¸­é†«çŸ¥è­˜åº«ã€‚
    å¥å­æ­£ç¢ºâ†’ç¨±è®š+æ­¡è¿ç¹¼çºŒï¼›å¥å­éŒ¯èª¤â†’é¼“å‹µ+æ›´æ­£+è§£é‡‹+æ­¡è¿ç¹¼çºŒã€‚
    ä½¿ç”¨ Markdown æ ¼å¼å„ªåŒ–å›é¥‹ã€‚
    """
    if not (text or "").strip():
        line_bot_api.push_message(user_id, text_with_quick_reply_writing("è«‹è²¼ä¸Šè¦ä¿®æ”¹çš„æ®µè½ã€‚"))
        return
    try:
        system_prompt = get_writing_mode_instructions()
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è«‹åˆ†æä»¥ä¸‹å¥å­æˆ–æ®µè½ï¼š\n\n{text[:1500]}"},
            ],
            max_tokens=800,
        )
        reply = (resp.choices[0].message.content or "").strip()
        if not reply:
            reply = "å·²æ”¶åˆ°ä½ çš„ç·´ç¿’ï¼æ­¡è¿ç¹¼çºŒè²¼ä¸Šå…¶ä»–å¥å­ï½"
        line_bot_api.push_message(user_id, text_with_quick_reply_writing(reply))
    except Exception:
        traceback.print_exc()
        line_bot_api.push_message(user_id, text_with_quick_reply_writing("è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"))

def quick_reply_writing():
    """å¯«ä½œä¿®è¨‚æ¨¡å¼ï¼šé›¢é–‹æ¨¡å¼ã€ç¹¼çºŒç·´ç¿’ã€‚"""
    return QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label="é›¢é–‹æ¨¡å¼", text="é›¢é–‹æ¨¡å¼")),
            QuickReplyButton(action=MessageAction(label="ç¹¼çºŒç·´ç¿’", text="ç¹¼çºŒç·´ç¿’")),
        ]
    )

def text_with_quick_reply_writing(content):
    return TextSendMessage(text=content, quick_reply=quick_reply_writing())

def _safe_get_mode(user_id):
    """å®‰å…¨å–å¾—ä½¿ç”¨è€…æ¨¡å¼ï¼ŒRedis å¤±æ•—æ™‚å›å‚³ tcmã€‚æ¯å€‹ user_id ç¨ç«‹ï¼Œç„¡ Global æ··æ·†ã€‚"""
    try:
        if not redis:
            print(f"[MODE] _safe_get_mode user_id={user_id} fallback=tcm reason=redis_none")
            return "tcm"
        key = f"user_mode:{user_id}"
        mode_val = redis.get(key)
        if mode_val is None:
            print(f"[MODE] _safe_get_mode user_id={user_id} fallback=tcm reason=key_missing_or_null")
            return "tcm"
        # Upstash å›å‚³ str æˆ– bytesï¼Œçµ±ä¸€æ­£è¦åŒ–
        if isinstance(mode_val, bytes):
            mode_str = mode_val.decode("utf-8", errors="replace").strip()
        else:
            mode_str = str(mode_val).strip()
        if not mode_str:
            print(f"[MODE] _safe_get_mode user_id={user_id} fallback=tcm reason=empty_value raw={repr(mode_val)}")
            return "tcm"
        return mode_str
    except Exception as e:
        print(f"[MODE] _safe_get_mode user_id={user_id} fallback=tcm reason=exception err={e}")
        return "tcm"

# --- AI æ ¸å¿ƒå‡½æ•¸ï¼ˆæ¨¡å¼è·¯ç”±å™¨ï¼‰---
def process_ai_request(event, user_id, text, is_voice=False):
    """State-Based Routerï¼šä¾ user_state (mode) åˆ‡æ› System Promptã€‚å¯«ä½œæ¨¡å¼å¼·åˆ¶èµ° revision_handlerï¼Œè·³é Assistant file_searchã€‚"""
    try:
        mode = _safe_get_mode(user_id)
        print(f"[MODE] process_ai_request user_id={user_id} mode={mode} routing={'revision' if mode == REVISION_MODE else 'assistant'}")
        if mode == REVISION_MODE:
            _revision_handler(user_id, text)
            return
        tag = "ğŸ©º ä¸­é†«å•ç­”"
        if mode == "speaking":
            tag = "ğŸ—£ï¸ å£èªªç·´ç¿’"
        elif mode == "writing":
            tag = "âœï¸ å¯«ä½œä¿®è¨‚"

        thread_id = None
        try:
            if redis:
                t_id = redis.get(f"user_thread:{user_id}")
                if t_id is not None:
                    thread_id = t_id.decode("utf-8") if hasattr(t_id, "decode") else str(t_id)
                    if thread_id == "None" or not thread_id.strip():
                        thread_id = None
        except Exception:
            pass

        if not thread_id:
            new_thread = client.beta.threads.create()
            thread_id = new_thread.id
            try:
                if redis:
                    redis.set(f"user_thread:{user_id}", thread_id)
            except Exception:
                pass

        if mode == "writing":
            mode_instructions = get_writing_mode_instructions()
        else:
            mode_instructions = get_rag_instructions()

        user_content = f"{mode_instructions}\n\nã€{tag}ã€‘\nä½¿ç”¨è€…çš„è©±ï¼š{text}"
        if mode == "tcm":
            user_content += "\n(æé†’ï¼šå›ç­”æœ«å°¾è«‹æä¾›åƒè€ƒè³‡æ–™å‡ºè™•)"

        client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=user_content,
        )
        run = client.beta.threads.runs.create(thread_id=thread_id, assistant_id=assistant_id)

        start_time = time.time()
        while run.status in ['queued', 'in_progress']:
            if time.time() - start_time > TIMEOUT_SECONDS:
                break
            time.sleep(1)
            run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)

        if run.status == 'completed':
            messages = client.beta.threads.messages.list(thread_id=thread_id)
            ai_reply = messages.data[0].content[0].text.value
            if mode == "tcm":
                ai_reply = ai_reply.rstrip() + SAFETY_DISCLAIMER
            log_question(redis, user_id, text)
            set_last_question(redis, user_id, text)
            set_last_assistant_message(redis, user_id, ai_reply)
            if mode == "tcm":
                line_bot_api.push_message(user_id, text_with_quick_reply_quiz(ai_reply + "\n\næ˜¯å¦è¦é€²è¡Œä¸€é¡Œå°æ¸¬é©—ï¼Ÿ"))
            else:
                line_bot_api.push_message(user_id, text_with_quick_reply(ai_reply))
        else:
            line_bot_api.push_message(user_id, text_with_quick_reply(TIMEOUT_MESSAGE))
    except Exception as e:
        print(f"CRITICAL ERROR: {traceback.format_exc()}")
        line_bot_api.push_message(user_id, text_with_quick_reply(TIMEOUT_MESSAGE))

# --- æ¯é€±å ±å‘Š Cronï¼ˆéœ€ CRON_SECRET é©—è­‰ï¼‰---
try:
    from api.weekly_report import run_weekly_report
except ImportError:
    from weekly_report import run_weekly_report

@app.route("/api/cron/weekly", methods=['GET', 'POST'])
def cron_weekly_report():
    """æ¯é€±å›ºå®šæ™‚é–“ç”± Vercel Cron æˆ–å¤–éƒ¨æ’ç¨‹å‘¼å«ï¼Œç”¢å‡º PDF ä¸¦å¯„é€è‡³ REPORT_EMAILã€‚"""
    secret = request.headers.get("Authorization") or request.args.get("secret") or ""
    expected = os.getenv("CRON_SECRET", "")
    if expected and secret != expected and secret != "Bearer " + expected:
        return "Unauthorized", 401
    try:
        ok, msg = run_weekly_report(redis, client)
        return (msg, 200) if ok else (msg, 500)
    except Exception as e:
        traceback.print_exc()
        return str(e)[:200], 500

# --- è·¯ç”±è¨­å®š ---
@app.route("/", methods=['GET'])
def home():
    return 'Line Bot Server is running!', 200

@app.route("/favicon.ico", methods=['GET'])
@app.route("/favicon.png", methods=['GET'])
def favicon():
    """é¿å…ç€è¦½å™¨/çˆ¬èŸ²è«‹æ±‚ favicon ç”¢ç”Ÿ 404 æ—¥èªŒã€‚"""
    return "", 204

def _run_voice_background(user_id, message_id, base_url, cron_secret):
    """Background Taskï¼šèªéŸ³è½‰éŒ„ã€GPT åˆ†æã€TTSã€Cloudinary ä¸Šå‚³ã€‚ä¸é˜»å¡ webhook å›å‚³ã€‚"""
    if base_url and cron_secret:
        try:
            requests.post(
                f"{base_url}/api/process-voice-async",
                json={"user_id": user_id, "message_id": message_id},
                headers={"Authorization": f"Bearer {cron_secret}"},
                timeout=30,
            )
        except Exception:
            try:
                _process_voice_sync(user_id, message_id)
            except Exception:
                traceback.print_exc()
    else:
        try:
            _process_voice_sync(user_id, message_id)
        except Exception:
            traceback.print_exc()


def _process_voice_sync(user_id, message_id):
    """æœ¬æ©Ÿ/ç¼ºå°‘ VERCEL_URL æ™‚åŒæ­¥åŸ·è¡ŒèªéŸ³è™•ç†ï¼ˆé¿å…éåŒæ­¥è§¸ç™¼å¤±æ•—æ™‚ç„¡å›æ‡‰ï¼‰ã€‚"""
    try:
        message_content = line_bot_api.get_message_content(message_id)
        tmp_dir = tempfile.gettempdir()
        temp_path = os.path.join(tmp_dir, f"{message_id}.m4a")
        try:
            with open(temp_path, "wb") as f:
                for chunk in message_content.iter_content():
                    f.write(chunk)
        except Exception:
            temp_path = os.path.join(os.path.dirname(__file__) or ".", f"{message_id}.m4a")
            with open(temp_path, "wb") as f:
                for chunk in message_content.iter_content():
                    f.write(chunk)

        with open(temp_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
        if os.path.isfile(temp_path):
            try:
                os.remove(temp_path)
            except OSError:
                pass

        transcript_text = (transcript.text or "").strip()
        line_bot_api.push_message(user_id, TextSendMessage(text=f"ğŸ¤ è¾¨è­˜å…§å®¹ï¼šã€Œ{transcript_text}ã€"))

        mode = _safe_get_mode(user_id)

        if mode == REVISION_MODE:
            _revision_handler(user_id, transcript_text)
            return
        if mode == "speaking":
            status, feedback, corrected_text = _evaluate_speech(transcript_text)
            if status == "Correct":
                line_bot_api.push_message(
                    user_id,
                    text_with_quick_reply_speak_practice("ç™¼éŸ³éå¸¸æ¨™æº–ï¼å¤ªæ£’äº†ï¼\n\nè¦å†ç·´ç¿’ä¸‹ä¸€å¥å—ï¼Ÿ"),
                )
            else:
                text_for_tts = corrected_text.strip() if corrected_text else transcript_text
                # å…ˆæ¨æ–‡å­—ï¼Œé™ä½é«”æ„Ÿç­‰å¾…ï¼›TTS + Cloudinary åœ¨å¾Œ
                line_bot_api.push_message(
                    user_id,
                    text_with_quick_reply(f"ğŸ“Š å£èªªç·´ç¿’å›é¥‹\n\n{feedback}\n\nğŸ”Š è«‹è·Ÿè‘—å”¸ï¼šã€Œ{text_for_tts}ã€"),
                )
                audio_url, duration_ms = _generate_tts_and_store(text_for_tts, voice=VOICE_COACH_TTS_VOICE)
                if audio_url and duration_ms:
                    line_bot_api.push_message(
                        user_id,
                        AudioSendMessage(original_content_url=audio_url, duration=duration_ms),
                    )
                    line_bot_api.push_message(
                        user_id,
                        text_with_quick_reply_speak_practice("ç¤ºç¯„èªéŸ³å·²é€ä¸Šï¼Œè¦å†ç·´ç¿’ä¸‹ä¸€å¥å—ï¼Ÿ"),
                    )
                else:
                    line_bot_api.push_message(
                        user_id,
                        text_with_quick_reply_speak_practice(
                            f"ä¿®æ­£æ–‡æœ¬ï¼š{text_for_tts}\n\nè¦å†ç·´ç¿’ä¸‹ä¸€å¥å—ï¼Ÿ"
                        ),
                    )
        else:
            if is_course_inquiry_intent(transcript_text):
                line_bot_api.push_message(user_id, TextSendMessage(text="æ­£åœ¨æŸ¥è©¢èª²å‹™è³‡æ–™..."))
                send_course_inquiry_flex(user_id)
            elif is_off_topic(transcript_text):
                line_bot_api.push_message(user_id, text_with_quick_reply(OFF_TOPIC_REPLY))
            else:
                process_ai_request(None, user_id, transcript_text, is_voice=True)
    except Exception:
        traceback.print_exc()
        line_bot_api.push_message(user_id, text_with_quick_reply("âŒ èªéŸ³è¾¨è­˜å¤±æ•—ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"))


@app.route("/api/process-voice-async", methods=["POST"])
def process_voice_async():
    """Background Taskï¼šæ¥æ”¶èªéŸ³ message_idï¼ŒåŸ·è¡Œ Whisper -> è©•ä¼° -> TTS -> Cloudinary -> pushã€‚"""
    secret = request.headers.get("Authorization") or request.headers.get("X-Internal-Secret") or ""
    expected = os.getenv("CRON_SECRET", "")
    if expected and secret not in (expected, "Bearer " + expected):
        return "Unauthorized", 401
    try:
        data = request.get_json(force=True, silent=True) or {}
        user_id = (data.get("user_id") or "").strip()
        message_id = (data.get("message_id") or "").strip()
        if not user_id or not message_id:
            return "Missing user_id or message_id", 400
        _process_voice_sync(user_id, message_id)
        return "OK", 200
    except Exception as e:
        traceback.print_exc()
        try:
            line_bot_api.push_message(
                (request.get_json(force=True, silent=True) or {}).get("user_id", ""),
                text_with_quick_reply("âŒ èªéŸ³è¾¨è­˜æˆ–è™•ç†å¤±æ•—ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"),
            )
        except Exception:
            pass
        return str(e)[:200], 500


@app.route("/audio/<token>", methods=['GET'])
def serve_audio(token):
    """æä¾› TTS éŸ³æª”çµ¦ LINE æ’­æ”¾ï¼ˆRedis æš«å­˜ï¼ŒTTL ç´„ 10 åˆ†é˜ï¼‰ã€‚"""
    try:
        if not redis:
            return "Not Found", 404
        b64 = redis.get(f"tts_audio:{token}")
        if not b64:
            return "Not Found", 404
        s = b64.decode("ascii") if hasattr(b64, "decode") else b64
        data = base64.b64decode(s)
        return Response(data, mimetype="audio/mpeg", direct_passthrough=True)
    except Exception:
        return "Not Found", 404

@app.route("/callback", methods=['POST'])
def callback():
    """LINE Webhook å”¯ä¸€å…¥å£ï¼ˆVercel rewrite â†’ æœ¬æª”ï¼‰ã€‚Postback / Message çš†ç”±æ­¤è™•ç†ã€‚"""
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        line_webhook_handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        traceback.print_exc()
        # ä»å›å‚³ 200ï¼Œé¿å… LINE é‡è©¦é€ æˆé‡è¤‡è§¸ç™¼
    return 'OK', 200

# --- äº‹ä»¶è™•ç† ---
@line_webhook_handler.add(PostbackEvent)
def handle_postback(event):
    data = (event.postback.data or "").strip()
    user_id = event.source.user_id
    try:
        if data == "action=course" or data == "action=weekly":
            send_course_inquiry_flex(user_id, reply_token=event.reply_token)
            return
        # mode=tcm / mode=speaking / mode=writingï¼ˆRich Menu åˆ‡æ›ï¼‰
        mode = data.split("=")[1].strip() if "=" in data else "tcm"
        mode_map = {"tcm": "ğŸ©º ä¸­é†«å•ç­”", "speaking": "ğŸ—£ï¸ å£èªªç·´ç¿’", "writing": "âœï¸ å¯«ä½œä¿®è¨‚"}
        redis_ok = False
        try:
            if redis:
                redis.set(f"user_mode:{user_id}", mode)
                redis_ok = True
                # å¯«å…¥å¾Œç«‹å³è®€å›é©—è­‰ï¼ˆä¾›é™¤éŒ¯ï¼‰
                verify = redis.get(f"user_mode:{user_id}")
                v = verify.decode("utf-8").strip() if isinstance(verify, bytes) else str(verify or "").strip()
                verified = (v == mode)
                print(f"[MODE] Postback user_id={user_id} set_mode={mode} redis_ok={redis_ok} verified={verified}")
        except Exception as e:
            print(f"[MODE] Postback user_id={user_id} set_mode={mode} redis_set_failed err={e}")
        # èˆ‡ CLI/æ–‡å­—æŒ‡ä»¤ä¸€è‡´çš„åˆ‡æ›è¨Šæ¯ï¼ˆå¯«ä½œä¿®è¨‚éœ€å«æ“ä½œæŒ‡å¼•ï¼‰
        if mode == REVISION_MODE:
            msg = "å·²åˆ‡æ›è‡³ã€âœï¸ å¯«ä½œä¿®è¨‚ã€‘æ¨¡å¼ï¼Œè«‹è²¼ä¸Šè¦ä¿®æ”¹çš„æ®µè½ã€‚"
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply_writing(msg))
        elif mode == "speaking":
            msg = "å·²åˆ‡æ›è‡³ã€ğŸ—£ï¸ å£èªªç·´ç¿’ã€‘æ¨¡å¼ï¼Œå¯å‚³é€èªéŸ³æˆ–æ–‡å­—ã€‚"
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply(msg))
        else:
            msg = f"å·²åˆ‡æ›è‡³ã€{mode_map.get(mode, mode)}ã€‘æ¨¡å¼"
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply(msg))
    except Exception as e:
        traceback.print_exc()
        try:
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply("é¸å–®è™•ç†ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"))
        except Exception:
            pass

@line_webhook_handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_text = (event.message.text or "").strip()
    try:
        # --- å¯«ä½œä¿®è¨‚æ¨¡å¼éš”é›¢ï¼šå„ªå…ˆåˆ¤æ–·ï¼Œè·³éä¸­é†«é‚è¼¯ ---
        current_mode = _safe_get_mode(user_id)
        print(f"[MODE] handle_message user_id={user_id} current_mode={current_mode} text_preview={user_text[:50]!r}")
        if current_mode == REVISION_MODE:
            print(f"[MODE] handle_message -> REVISION_MODE branch, skipping TCM Assistant")
            if user_text == "å¯«ä½œä¿®æ”¹":
                line_bot_api.reply_message(
                    event.reply_token,
                    text_with_quick_reply_writing("ä½ å·²åœ¨ã€âœï¸ å¯«ä½œä¿®è¨‚ã€‘æ¨¡å¼ï½è«‹è²¼ä¸Šè¦ä¿®æ”¹çš„æ®µè½ã€‚"),
                )
                return
            if user_text == "é›¢é–‹æ¨¡å¼":
                try:
                    if redis:
                        redis.set(f"user_mode:{user_id}", "tcm")
                except Exception:
                    pass
                line_bot_api.reply_message(
                    event.reply_token,
                    text_with_quick_reply("å·²é›¢é–‹å¯«ä½œä¿®è¨‚æ¨¡å¼ï¼Œå·²åˆ‡æ›å›ä¸­é†«å•ç­”æ¨¡å¼ã€‚"),
                )
                return
            if user_text == "ç¹¼çºŒç·´ç¿’":
                line_bot_api.reply_message(
                    event.reply_token,
                    text_with_quick_reply_writing("è«‹è²¼ä¸Šè¦ä¿®æ”¹çš„æ®µè½ã€‚"),
                )
                return
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="æ­£åœ¨åˆ†æä½ çš„å¯«ä½œ..."))
            _revision_handler(user_id, user_text)
            return

        # èª²å‹™æŸ¥è©¢ï¼æœ¬é€±é‡é»ï¼šçµ±ä¸€ä»¥ Flex Message å›å‚³
        if is_course_inquiry_intent(user_text):
            send_course_inquiry_flex(user_id, reply_token=event.reply_token)
            return

        # å°æ¸¬é©—å¾Œï¼ˆèˆŠç‹€æ…‹ç›¸å®¹ï¼‰ï¼šå­¸ç”Ÿçš„å›ç­”è¦–ç‚ºæ–°å•é¡Œï¼Œäº¤ç”± AI è™•ç†
        if get_user_state(redis, user_id) == STATE_QUIZ_WAITING:
            set_user_state(redis, user_id, STATE_NORMAL)
            clear_quiz_data(redis, user_id)
            clear_quiz_pending(redis, user_id)
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="æ­£åœ¨åˆ†æä¸­..."))
            process_ai_request(event, user_id, user_text, is_voice=False)
            return

        # ä¸»å‹•è¤‡ç¿’ï¼šä½¿ç”¨è€…é¸æ“‡ã€Œè¦è¤‡ç¿’ç­†è¨˜ã€
        if user_text == "è¦è¤‡ç¿’ç­†è¨˜":
            cat = get_pending_review_category(redis, user_id)
            clear_pending_review_category(redis, user_id)
            if cat:
                note = generate_review_note(client, cat)
                clear_weak_category(redis, user_id, cat)
                line_bot_api.reply_message(event.reply_token, text_with_quick_reply(f"ğŸ“ ã€{cat}ã€‘è¤‡ç¿’ç­†è¨˜\n\n{note}"))
            else:
                line_bot_api.reply_message(event.reply_token, text_with_quick_reply("å¥½çš„ï¼Œæœ‰éœ€è¦å†è·Ÿæˆ‘èªªï½"))
            return
        if user_text == "ä¸è¦è¤‡ç¿’ç­†è¨˜":
            clear_pending_review_category(redis, user_id)
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply("å¥½çš„ï¼Œæœ‰éœ€è¦å†è·Ÿæˆ‘èªªï½"))
            return

        # ä¸»å‹•è¤‡ç¿’ï¼šåµæ¸¬åˆ°å¼±é …ä¸”è¶…éå†·å»æœŸ â†’ è©¢å•æ˜¯å¦æ•´ç†è¤‡ç¿’ç­†è¨˜
        weak = get_weak_categories(redis, user_id, min_count=2)
        if weak and (time.time() - get_last_review_ask(redis, user_id)) > 7 * 24 * 3600:
            category = next(iter(weak.keys()), None)
            if category:
                set_last_review_ask(redis, user_id)
                set_pending_review_category(redis, user_id, category)
                line_bot_api.reply_message(
                    event.reply_token,
                    text_with_quick_reply_review_ask(f"ç™¼ç¾ä½ å°ã€Œ{category}ã€é€™éƒ¨åˆ†è¼ƒä¸ç†Ÿï¼Œéœ€è¦å¹«ä½ æ•´ç†è¤‡ç¿’ç­†è¨˜å—ï¼Ÿ"),
                )
                return

        # å°æ¸¬é©—ï¼šé»æ“Šã€Œå¦ã€â†’ å‹å–„å›è¦†ï¼Œä¿æŒä¸€èˆ¬å•ç­”æ¨¡å¼
        if user_text == "å¦":
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply("æ²’å•é¡Œï¼å¦‚æœæœ‰å…¶ä»–æƒ³äº†è§£çš„ï¼Œæ­¡è¿éš¨æ™‚æå•ã€‚"))
            return
        # å°æ¸¬é©—ï¼šé»æ“Šã€Œæ˜¯ã€â†’ é‡å°å‰›æ‰è¨è«–çš„ä¸»é¡Œå‡ºé¡Œï¼ˆå­¸ç”Ÿçš„å›ç­”å°‡è¦–ç‚ºæ–°å•é¡Œï¼‰
        if user_text == "æ˜¯":
            discussed_topic = get_last_question(redis, user_id)
            last_ctx = get_last_assistant_message(redis, user_id)
            question, _, _ = generate_dynamic_quiz(client, discussed_topic=discussed_topic, last_context=last_ctx)
            flex_msg = build_quiz_flex_message(question)
            line_bot_api.reply_message(event.reply_token, flex_msg)
            return

        if user_text == "æœ¬é€±é‡é»":
            send_course_inquiry_flex(user_id, reply_token=event.reply_token)
            return

        if user_text == "å£èªªç·´ç¿’":
            try:
                if redis:
                    redis.set(f"user_mode:{user_id}", "speaking")
            except Exception:
                pass
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply("å·²åˆ‡æ›è‡³ã€ğŸ—£ï¸ å£èªªç·´ç¿’ã€‘æ¨¡å¼ï¼Œå¯å‚³é€èªéŸ³æˆ–æ–‡å­—ã€‚"))
            return
        if user_text == "å¯«ä½œä¿®æ”¹":
            try:
                if redis:
                    redis.set(f"user_mode:{user_id}", REVISION_MODE)
                    v = redis.get(f"user_mode:{user_id}")
                    v_str = v.decode("utf-8").strip() if isinstance(v, bytes) else str(v or "").strip()
                    print(f"[MODE] å¯«ä½œä¿®æ”¹ user_id={user_id} set_mode=writing verified={v_str == REVISION_MODE}")
                else:
                    print(f"[MODE] å¯«ä½œä¿®æ”¹ user_id={user_id} redis_none mode_not_persisted")
            except Exception as e:
                print(f"[MODE] å¯«ä½œä¿®æ”¹ user_id={user_id} redis_set_failed err={e}")
            line_bot_api.reply_message(
                event.reply_token,
                text_with_quick_reply_writing("å·²åˆ‡æ›è‡³ã€âœï¸ å¯«ä½œä¿®è¨‚ã€‘æ¨¡å¼ï¼Œè«‹è²¼ä¸Šè¦ä¿®æ”¹çš„æ®µè½ã€‚"),
            )
            return
        if user_text == "ç·´ç¿’ä¸‹ä¸€å¥":
            mode = _safe_get_mode(user_id)
            if mode == "speaking":
                line_bot_api.reply_message(
                    event.reply_token,
                    text_with_quick_reply_speak_practice("è«‹å‚³é€èªéŸ³è¨Šæ¯é–‹å§‹ç·´ç¿’ï½æˆ‘æœƒå¹«ä½ åˆ†æç™¼éŸ³èˆ‡æ–‡æ³•ã€‚\n\nè¦å†ç·´ç¿’ä¸‹ä¸€å¥å—ï¼Ÿ"),
                )
                return
        if user_text == "çµæŸç·´ç¿’":
            try:
                if redis:
                    redis.set(f"user_mode:{user_id}", "tcm")
            except Exception:
                pass
            line_bot_api.reply_message(
                event.reply_token,
                text_with_quick_reply("å·²çµæŸå£èªªç·´ç¿’ï¼Œå·²åˆ‡æ›å›ä¸­é†«å•ç­”æ¨¡å¼ã€‚"),
            )
            return

        # ç²¾æº–éæ¿¾ï¼šåƒ…å®Œå…¨èˆ‡ä¸­é†«/é†«ç™‚å­¸è¡“ç„¡é—œï¼ˆé–’èŠã€å¨›æ¨‚ã€ç§äººï¼‰â†’ åƒ…ä¾›å­¸æ¥­ä½¿ç”¨
        if is_off_topic(user_text):
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply(OFF_TOPIC_REPLY))
            return

        mode = _safe_get_mode(user_id)
        mode_name = {"tcm": "ğŸ©º ä¸­é†«å•ç­”", "speaking": "ğŸ—£ï¸ å£èªªç·´ç¿’", "writing": "âœï¸ å¯«ä½œä¿®è¨‚"}.get(mode, "ğŸ©º ä¸­é†«å•ç­”")

        # å…ˆå›è¦†ã€Œæ­£åœ¨åˆ†æã€ï¼Œå†åŒæ­¥åŸ·è¡Œ AIï¼ˆVercel èƒŒæ™¯åŸ·è¡Œç·’å¯èƒ½è¢«çµ‚æ­¢ï¼Œæ”¹å›åŒæ­¥ä»¥ç¢ºä¿æœ‰å›è¦†ï¼‰
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æ­£åœ¨ä»¥ã€{mode_name}ã€‘æ¨¡å¼åˆ†æä¸­..."))
        process_ai_request(event, user_id, user_text, is_voice=False)
    except Exception as e:
        traceback.print_exc()
        err_msg = str(e).strip()[:100]
        try:
            line_bot_api.reply_message(event.reply_token, text_with_quick_reply(f"è™•ç†è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚ï¼ˆ{err_msg}ï¼‰"))
        except Exception:
            try:
                line_bot_api.push_message(user_id, text_with_quick_reply(f"è™•ç†è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚ï¼ˆ{err_msg}ï¼‰"))
            except Exception:
                pass

@line_webhook_handler.add(MessageEvent, message=AudioMessage)
def handle_audio(event):
    """å£èªªæ•™ç·´ï¼šWebhook é ˆåœ¨ 2 ç§’å…§å›å‚³ 200ï¼›èªéŸ³è½‰éŒ„ï¼GPTï¼TTSï¼Cloudinary å…¨åœ¨ Background åŸ·è¡Œã€‚"""
    user_id = event.source.user_id
    message_id = event.message.id

    # 1. ç«‹å³å›è¦†ä½¿ç”¨è€…ï¼ˆå”¯ä¸€å¿…è¦çš„é˜»å¡å‘¼å«ï¼Œé€šå¸¸ <1.5sï¼‰
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ğŸ™ï¸ æ­£åœ¨è½‰æ›èªéŸ³..."))

    # 2. è§¸ç™¼ Background Taskï¼ˆèªéŸ³è½‰éŒ„ã€GPTã€TTSã€Cloudinary åœ¨ /api/process-voice-async ç¨ç«‹åŸ·è¡Œï¼‰
    vercel_url = (os.getenv("VERCEL_URL") or "").strip().rstrip("/")
    base_url = f"https://{vercel_url}" if vercel_url and not vercel_url.startswith("http") else (vercel_url or "")
    cron_secret = os.getenv("CRON_SECRET", "")

    if base_url and cron_secret:
        # Vercelï¼šåŒæ­¥ fire POSTï¼Œtimeout=0.8sï¼Œè«‹æ±‚é€å‡ºå³è§¸ç™¼æ–° invocationï¼Œä¸é˜»å¡
        try:
            requests.post(
                f"{base_url}/api/process-voice-async",
                json={"user_id": user_id, "message_id": message_id},
                headers={"Authorization": f"Bearer {cron_secret}"},
                timeout=0.8,
            )
        except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectTimeout):
            pass  # é æœŸï¼šasync å·²è§¸ç™¼ï¼Œæœ¬å‡½æ•¸ä¸ç­‰å¾…å…¶å®Œæˆ
        except Exception:
            threading.Thread(
                target=_run_voice_background,
                args=(user_id, message_id, base_url, cron_secret),
                daemon=True,
            ).start()  # é€£ç·šå¤±æ•—æ™‚ç”± thread åŸ·è¡Œ fallback
    else:
        # æœ¬æ©Ÿï¼šthread ä¸­åŸ·è¡Œï¼Œé¿å…é˜»å¡
        threading.Thread(
            target=_run_voice_background,
            args=(user_id, message_id, base_url, cron_secret),
            daemon=True,
        ).start()


if __name__ == "__main__":
    # æœ¬åœ°å¿«é€Ÿæ¸¬è©¦ï¼špython -m api.index æˆ– python api/index.pyï¼ˆå¾å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
    # å†é–‹ä¸€å€‹çµ‚ç«¯åŸ·è¡Œ ngrok http 5000ï¼Œä¸¦å°‡ LINE Webhook æ”¹ç‚º https://YOUR-NGROK-URL/callback
    app.run(host="0.0.0.0", port=5000, debug=True)
